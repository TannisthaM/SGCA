library(MASS)
library(stats)
library(pracma)
library(tidyverse)
library(Matrix)
library(tidyr)

matmul <- function(A, B) {
  if (requireNamespace("SMUT", quietly = TRUE)) {
    SMUT::eigenMapMatMult(A, B)
  } else {
    A %*% B
  }
}

soft_threshold <- function(X, T) {
  # T can be scalar or same shape as X
  sign(X) * pmax(abs(X) - T, 0)
}

sym_inv_sqrt <- function(S, eps = 1e-10) {
  S <- (S + t(S))/2
  ee <- eigen(S, symmetric = TRUE)
  vals <- pmax(ee$values, eps)
  V <- ee$vectors
  matmul(matmul(V, diag(1/sqrt(vals), nrow = length(vals))), t(V))
}

top_eigs_sym <- function(A, r) {
  A <- (A + t(A))/2
  if (requireNamespace("RSpectra", quietly = TRUE) && r < nrow(A)) {
    out <- RSpectra::eigs_sym(A, k = r, which = "LM")
    list(values = Re(out$values), vectors = Re(out$vectors))
  } else {
    ev <- eigen(A, symmetric = TRUE)
    list(values = ev$values[seq_len(r)], vectors = ev$vectors[, seq_len(r), drop = FALSE])
  }
}

.block_indices <- function(plist) {
  edges <- c(0, cumsum(plist))
  lapply(seq_along(plist), function(i) (edges[i] + 1):edges[i + 1])
}


# Allow passing S plus optional S0 (otherwise derive S0 by copying diagonal blocks)
.build_sigma_pair <- function(S, plist, S0 = NULL) {
  S <- (S + t(S)) / 2
  ptot <- nrow(S)
  stopifnot(sum(plist) == ptot)
  
  if (is.null(S0)) {
    S0 <- matrix(0, ptot, ptot)
    idxs <- .block_indices(plist)
    for (idx in idxs) S0[idx, idx] <- S[idx, idx]
  } else {
    S0 <- (S0 + t(S0)) / 2
  }
  list(Sigma = S, Sigma0 = S0)
}

## row/group proxes only used if you select penalties other than "l1"
.prox_l21_rows <- function(X, tau, mask, row_weights) {
  Z <- X
  p <- nrow(X)
  for (i in seq_len(p)) {
    v <- X[i, ] * mask[i, ]
    nrm <- sqrt(sum(v^2))
    if (nrm > 0) {
      shrink <- max(1 - (tau * row_weights[i]) / nrm, 0)
      v <- v * shrink
    }
    Z[i, ] <- v + X[i, ] * (1 - mask[i, ])
  }
  (Z + t(Z))/2
}

.prox_l21_groups <- function(X, lambda_over_rho, groups_l21 = list(), group_weights = NULL) {
  if (length(groups_l21) == 0) return(X)
  if (is.null(group_weights)) group_weights <- rep(1, length(groups_l21))
  Z <- X
  for (g in seq_along(groups_l21)) {
    idx <- groups_l21[[g]]
    if (is.matrix(idx) && ncol(idx) == 2) {
      vals <- X[cbind(idx[,1], idx[,2])]
    } else {
      vals <- X[idx]
    }
    nrm <- sqrt(sum(vals^2))
    shrink <- if (nrm > 0) max(1 - lambda_over_rho * group_weights[g] / nrm, 0) else 0
    if (is.matrix(idx) && ncol(idx) == 2) {
      Z[cbind(idx[,1], idx[,2])] <- vals * shrink
    } else {
      Z[idx] <- vals * shrink
    }
  }
  (Z + t(Z))/2
}




# sgcar_cv_folds_parallel.R
# -------------------------------------------------------------------
# Cross-validation for SGCar/SGCA ADMM solver, parallelized over folds.
# Each worker handles one fold and runs lambdas sequentially with warm starts.
#
# Optional packages used if available:
#   - SMUT       : faster matrix multiplication (matmul)
#   - RSpectra   : faster top eigenvectors
#   - RhpcBLASctl: control BLAS/OMP threads per worker
#
# Author: generated by ChatGPT
# -------------------------------------------------------------------

# ---- null coalescing (avoid tidyverse dependency) ----
`%||%` <- function(a, b) if (!is.null(a)) a else b

# ---- parallel backend helper (user-provided, with no hard dependency on crayon) ----
setup_parallel_backend <- function(num_cores = NULL, verbose = FALSE) {
  if (is.null(num_cores)) {
    n_cores_str <- Sys.getenv("SLURM_CPUS_PER_TASK")
    num_cores <- if (n_cores_str == "") (parallel::detectCores() - 1L) else as.integer(n_cores_str)
  }
  num_cores <- max(1L, as.integer(num_cores))
  if (isTRUE(verbose)) {
    cat(sprintf("\nAttempting to set up parallel backend with %d cores.\n", num_cores))
  }

  cl <- NULL
  tryCatch({
    if (.Platform$OS.type == "unix") {
      if (isTRUE(verbose)) cat("Unix-like system detected. Trying FORK backend...\n")
      cl <- parallel::makeCluster(num_cores, type = "FORK")
    } else {
      if (isTRUE(verbose)) cat("Windows system detected. Trying PSOCK backend...\n")
      cl <- parallel::makeCluster(num_cores, type = "PSOCK")
    }
  }, error = function(e_fork) {
    msg <- conditionMessage(e_fork)
    if (requireNamespace("crayon", quietly = TRUE)) {
      cat(crayon::yellow("Initial backend setup failed: ", msg, "\n", sep = ""))
    } else {
      cat("Initial backend setup failed: ", msg, "\n", sep = "")
    }
    cat("Attempting fallback PSOCK backend...\n")

    tryCatch({
      cl <<- parallel::makeCluster(num_cores, type = "PSOCK")
    }, error = function(e_psock) {
      msg2 <- conditionMessage(e_psock)
      if (requireNamespace("crayon", quietly = TRUE)) {
        cat(crayon::red("PSOCK setup also failed: ", msg2, "\n", sep = ""))
      } else {
        cat("PSOCK setup also failed: ", msg2, "\n", sep = "")
      }
      cl <<- NULL
    })
  })

  cl
}

# -------------------------------------------------------------------
# CV helpers
# -------------------------------------------------------------------
.make_folds <- function(n, K, seed = NULL) {
  if (!is.null(seed)) set.seed(seed)
  idx <- sample.int(n)
  fold_id <- cut(seq_len(n), breaks = K, labels = FALSE)
  out <- integer(n)
  out[idx] <- fold_id
  out
}

.mask_from_part <- function(p, part = c("all", "offdiag", "block_off"), p_list = NULL) {
  part <- match.arg(part)
  M <- matrix(TRUE, p, p)
  if (part == "offdiag") {
    diag(M) <- FALSE
  } else if (part == "block_off") {
    if (is.null(p_list)) stop("p_list is required when part='block_off'.")
    start <- 1L
    for (sz in p_list) {
      idx <- start:(start + sz - 1L)
      M[idx, idx] <- FALSE
      start <- start + sz
    }
  }
  M
}

.bd_from_S <- function(S, p_list) {
  ptot <- sum(p_list)
  S0 <- matrix(0, ptot, ptot)
  offs <- c(0L, cumsum(p_list))
  for (j in seq_along(p_list)) {
    id <- (offs[j] + 1L):offs[j + 1L]
    S0[id, id] <- S[id, id]
  }
  S0
}

# Held-out loss: Frobenius norm of residual in the same objective used in training.
.cv_loss <- function(U_hat, Sigma_val, p_list) {
  Sigma_val0 = .bd_from_S(Sigma_val, p_list)
  normalization = t(U_hat) %*% Sigma_val0 %*% U_hat
  return(-sum(diag(solve(normalization) %*% t(U_hat) %*% Sigma_val %*% U_hat)))
}

# -------------------------------------------------------------------
# Warm-startable ADMM core (split into prepare + run)
# -------------------------------------------------------------------

# Prepare constants for repeated lambda fits on the *same* (Sigma, Sigma0).
# This is what makes the warm-start path efficient.
.admm_sgca_prepare <- function(Sigma, Sigma0,
                              rho = NA,
                              p_list = NULL,
                              penalty = c("l1", "l21_rows", "l21_groups"),
                              penalize = c("offdiag", "all", "block"),
                              weight = NULL,
                              row_weights = NULL,
                              groups_l21 = NULL,
                              group_weights = NULL,
                              symmetrize_z = TRUE,
                              sparsity_threshold = 1e-4) {

  penalty <- match.arg(penalty)
  penalize <- match.arg(penalize)
  


  Sigma <- (Sigma + t(Sigma)) / 2
  Sigma0 <- (Sigma0 + t(Sigma0)) / 2

  p_all <- nrow(Sigma0)

  # EVD of Sigma0
  ev0 <- eigen(Sigma0, symmetric = TRUE)
  U0 <- ev0$vectors
  lam2 <- pmax(ev0$values, 0)
  Lam2 <- diag(lam2, nrow = length(lam2))
  
  if (is.na(rho)){
    d <- lam2
    rho  = stats::median(outer(d^2, d^2))
  }

  # constants for the C update in Sigma0-basis
  Sigma_tilde <- matmul(t(U0), matmul(Sigma, U0))
  const_rhs <- matmul(matmul(Lam2, Sigma_tilde), Lam2)

  outer_term <- outer(lam2^2, lam2^2, `*`)
  denom <- rho + outer_term

  # masks & weights for l1 / l21_rows
  mask <- matrix(1, p_all, p_all)
  if (penalize == "offdiag") diag(mask) <- 0
  if (penalize == "block") {
    stopifnot(!is.null(p_list), sum(p_list) == p_all)
    count <- 0L
    for (u in p_list) {
      mask[(count + 1L):(count + u), (count + 1L):(count + u)] <- 0
      count <- count + u
    }
  }

  if (is.null(weight)) weight <- matrix(1, p_all, p_all)
  if (is.null(row_weights)) row_weights <- rep(1, p_all)

  # Sigma0^(1/2) (only needed if you later compute canonical directions)
  Sigma0_sqrt <- matmul(U0, matmul(diag(sqrt(lam2), nrow = length(lam2)), t(U0)))

  list(
    p_all = p_all,
    Sigma0 = Sigma0,
    U0 = U0,
    lam2 = lam2,
    Lam2 = Lam2,
    const_rhs = const_rhs,
    outer_term = outer_term,
    denom = denom,
    rho = rho,
    penalty = penalty,
    penalize = penalize,
    p_list = p_list,
    mask = mask,
    weight = weight,
    row_weights = row_weights,
    groups_l21 = groups_l21 %||% list(),
    group_weights = group_weights,
    symmetrize_z = symmetrize_z,
    sparsity_threshold = sparsity_threshold,
    Sigma0_sqrt = Sigma0_sqrt
  )
}

# Run ADMM for a single lambda, with optional warm start.
.admm_sgca_run <- function(prep,
                          lambda,
                          r,
                          init = NULL,
                          warm_start = c("CZU", "C_only", "none"),
                          max_iter = 4000,
                          abs_tol = 1e-4,
                          rel_tol = 1e-3,
                          adapt_rho = FALSE,
                          mu = 10,
                          tau_incr = 2,
                          tau_decr = 2,
                          verbose = FALSE,
                          compute_canon = FALSE) {

  warm_start <- match.arg(warm_start)

  p_all <- prep$p_all
  U0 <- prep$U0
  lam2 <- prep$lam2
  const_rhs <- prep$const_rhs
  outer_term <- prep$outer_term

  rho <- prep$rho
  denom <- prep$denom

  # init states
  C <- matrix(0, p_all, p_all)
  Z <- C
  U_dual <- C

  if (!is.null(init) && warm_start != "none") {
    if (!is.null(init$C) && all(dim(init$C) == c(p_all, p_all))) C <- init$C
    if (warm_start == "CZU") {
      if (!is.null(init$Z) && all(dim(init$Z) == c(p_all, p_all))) Z <- init$Z else Z <- C
      if (!is.null(init$U_dual) && all(dim(init$U_dual) == c(p_all, p_all))) U_dual <- init$U_dual
      if (!is.null(init$rho) && is.finite(init$rho)) {
        rho <- as.numeric(init$rho)
        denom <- rho + outer_term
      }
    } else if (warm_start == "C_only") {
      Z <- C
      U_dual <- matrix(0, p_all, p_all)
    }
  }

  penalty <- prep$penalty
  mask <- prep$mask
  weight <- prep$weight
  row_weights <- prep$row_weights
  groups_l21 <- prep$groups_l21
  group_weights <- prep$group_weights
  symmetrize_z <- prep$symmetrize_z

  converged <- FALSE
  iter_final <- 0L

  for (iter in seq_len(max_iter)) {
    iter_final <- iter
    Z_prev <- Z

    # ----- C update (closed form) -----
    rhs_tilde <- rho * matmul(t(U0), matmul(Z - U_dual, U0)) + const_rhs
    C_tilde <- rhs_tilde / denom
    C <- matmul(U0, matmul(C_tilde, t(U0)))

    # ----- Z update (prox) -----
    Z_tilde <- C + U_dual
    if (penalty == "l1") {
      if (all(weight == 1) && all(mask == 1)) {
        Z <- soft_threshold(Z_tilde, lambda / rho)
      } else {
        Z <- Z_tilde
        idx <- (mask == 1)
        Z[idx] <- soft_threshold(Z_tilde[idx], (lambda / rho) * weight[idx])
      }
    } else if (penalty == "l21_rows") {
      Z <- .prox_l21_rows(Z_tilde, tau = (lambda / rho), mask = mask, row_weights = row_weights)
    } else if (penalty == "l21_groups") {
      Z <- .prox_l21_groups(Z_tilde, lambda_over_rho = (lambda / rho),
                            groups_l21 = groups_l21,
                            group_weights = group_weights)
    }

    if (symmetrize_z) Z <- (Z + t(Z)) / 2

    # ----- dual update (scaled) -----
    U_dual <- U_dual + (C - Z)

    # ----- diagnostics / stopping -----
    r_norm <- base::norm(C - Z, "F")
    s_norm <- rho * base::norm(Z - Z_prev, "F")
    eps_pri <- sqrt(p_all * p_all) * abs_tol + rel_tol * max(base::norm(C, "F"), base::norm(Z, "F"))
    eps_dual <- sqrt(p_all * p_all) * abs_tol + rel_tol * rho * base::norm(U_dual, "F")

    if (isTRUE(verbose) && iter %% 50 == 0) {
      cat(sprintf("iter %5d  r=%.3e  s=%.3e  eps_pri=%.3e  eps_dual=%.3e  rho=%.3g\n",
                  iter, r_norm, s_norm, eps_pri, eps_dual, rho))
    }

    if (r_norm <= eps_pri && s_norm <= eps_dual) {
      converged <- TRUE
      break
    }

    # ----- adaptive rho (optional) -----
    if (isTRUE(adapt_rho)) {
      if (r_norm > mu * s_norm) {
        rho <- rho * tau_incr
        U_dual <- U_dual / tau_incr
        denom <- rho + outer_term
      } else if (s_norm > mu * r_norm) {
        rho <- rho / tau_decr
        U_dual <- U_dual * tau_decr
        denom <- rho + outer_term
      }
    }
  }

  # By default, CV only needs C. Canonical directions are optional.
  out <- list(
    C = C,
    Z = Z,
    U_dual = U_dual,
    rho = rho,
    iter = iter_final,
    converged = converged,
    C_sparsity = mean(abs(C) < prep$sparsity_threshold)
  )

  if (isTRUE(compute_canon)) {
    Sigma0_sqrt <- prep$Sigma0_sqrt
    target <- matmul(Sigma0_sqrt, matmul(C, Sigma0_sqrt))
    eU <- top_eigs_sym(target, r)
    U_svd <- eU$vectors
    # Not over ---- need to compute the correct normalization
    if (r == 1){
      U_canon <- matmul(C, Sigma0_sqrt) %*% U_svd  * 1/eU$values
    }else{
      U_canon <- matmul(C, Sigma0_sqrt) %*% U_svd %*% diag(1/eU$values)
    }
    

    # normalize to enforce U^T Sigma0 U = I
    #B <- matmul(t(U_svd), matmul(prep$Sigma0, U_svd))
    #U_canon <- matmul(U_svd, sym_inv_sqrt(B))

    out$U <- U_canon
    out$cor <- sqrt(pmax(eU$values, 0))
    out$U_sparsity <- mean(abs(U_canon) < prep$sparsity_threshold)
  }

  out
}

# -------------------------------------------------------------------
# Main CV function: parallel over folds, warm start over lambdas
# -------------------------------------------------------------------

sgcar_cv_folds <- function(
  X,
  p_list,
  lambdas,
  r,
  K = 5,
  folds = NULL,
  seed = NULL,
  penalty = c("l1", "l21_rows", "l21_groups"),
  penalize = c("offdiag", "all", "block"),
  loss_part = c("auto", "all", "offdiag", "block_off"),
  loss_weight = NULL,
  relative_loss = TRUE,
  lambda_order = c("decreasing", "increasing", "as_is"),
  warm_start = c("CZU", "C_only", "none"),
  # solver controls
  rho = 1,
  weight = NULL,
  row_weights = NULL,
  groups_l21 = NULL,
  group_weights = NULL,
  symmetrize_z = TRUE,
  max_iter = 4000,
  abs_tol = 1e-4,
  rel_tol = 1e-3,
  adapt_rho = FALSE,
  mu = 10,
  tau_incr = 2,
  tau_decr = 2,
  sparsity_threshold = 1e-4,
  # parallel controls
  parallel = TRUE,
  nb_cores = NULL,
  blas_threads = 1,
  rng_seed = NULL,
  verbose = TRUE
) {

  penalty <- match.arg(penalty)
  penalize <- match.arg(penalize)
  loss_part <- match.arg(loss_part)
  lambda_order <- match.arg(lambda_order)
  warm_start <- match.arg(warm_start)

  .log <- function(...) if (isTRUE(verbose)) cat(sprintf(...), "\n")

  X <- as.matrix(X)
  n <- nrow(X)
  p <- ncol(X)
  stopifnot(sum(p_list) == p)
  stopifnot(length(lambdas) >= 1)
  stopifnot(r >= 1, r <= p)

  # Folds
  if (is.null(folds)) {
    stopifnot(K >= 2, K <= n)
    folds <- .make_folds(n, K, seed = seed)
  } else {
    stopifnot(length(folds) == n)
    K <- length(unique(folds))
    stopifnot(K >= 2)
  }

  # Effective loss part
  part_eff <- if (loss_part == "auto") {
    if (penalize == "offdiag") "offdiag" else if (penalize == "block") "block_off" else "all"
  } else {
    loss_part
  }

  lambdas <- as.numeric(lambdas)
  L <- length(lambdas)

  .log("[cv] n=%d p=%d | K=%d folds | L=%d lambdas", n, p, K, L)
  .log("[cv] penalty=%s | penalize=%s | loss_part=%s | warm_start=%s | lambda_order=%s",
       penalty, penalize, part_eff, warm_start, lambda_order)

  # Full-data second moment
  M_full <- crossprod(X)
  S_full <- (M_full / n)
  S_full <- (S_full + t(S_full)) / 2
  S0_full <- .bd_from_S(S_full, p_list)

  # Precompute fold stats (down-dated from M_full)
  .log("[cv] precompute fold moments...")
  fold_stats <- vector("list", K)
  for (k in seq_len(K)) {
    idx_val <- which(folds == k)
    n_val <- length(idx_val)
    n_tr <- n - n_val
    if (n_tr <= 1) stop("A training fold has <= 1 sample. Reduce K.")

    Xval <- X[idx_val, , drop = FALSE]
    M_val <- crossprod(Xval)

    S_va <- (M_val / n_val)
    S_va <- (S_va + t(S_va)) / 2

    S_tr <- ((M_full - M_val) / n_tr)
    S_tr <- (S_tr + t(S_tr)) / 2

    S0_tr <- .bd_from_S(S_tr, p_list)
    S0_va <- .bd_from_S(S_va, p_list)

    fold_stats[[k]] <- list(
      k = k,
      S_tr = S_tr,
      S0_tr = S0_tr,
      S_va = S_va,
      S0_va = S0_va
    )
  }
  .log("[cv] precompute done")

  # Storage: L x K
  cv_mat <- matrix(NA_real_, nrow = L, ncol = K,
                   dimnames = list(paste0("lambda=", signif(lambdas, 6)),
                                   paste0("Fold", seq_len(K))))

  # Lambda order for warm start
  lam_ord <- switch(lambda_order,
    decreasing = order(lambdas, decreasing = TRUE),
    increasing = order(lambdas, decreasing = FALSE),
    as_is = seq_along(lambdas)
  )
  lam_rev <- integer(L)
  lam_rev[lam_ord] <- seq_len(L)

  # Worker function: one fold, all lambdas sequentially (warm start)
  .worker_fold <- function(fs) {
    k <- fs$k

    prep <- .admm_sgca_prepare(
      Sigma = fs$S_tr,
      Sigma0 = fs$S0_tr,
      rho = rho,
      p_list = p_list,
      penalty = penalty,
      penalize = penalize,
      weight = weight,
      row_weights = row_weights,
      groups_l21 = groups_l21,
      group_weights = group_weights,
      symmetrize_z = symmetrize_z,
      sparsity_threshold = sparsity_threshold
    )

    losses <- rep(NA_real_, L)
    state <- NULL

    # iterate lambdas in chosen order
    for (jj in seq_along(lam_ord)) {
      li <- lam_ord[jj]
      lam <- lambdas[li]

      fit <- tryCatch({
        .admm_sgca_run(
          prep = prep,
          lambda = lam,
          r = r,
          init = state,
          warm_start = warm_start,
          max_iter = max_iter,
          abs_tol = abs_tol,
          rel_tol = rel_tol,
          adapt_rho = adapt_rho,
          mu = mu,
          tau_incr = tau_incr,
          tau_decr = tau_decr,
          verbose = FALSE,
          compute_canon = TRUE
        )
      }, error = function(e) {
        list(error = conditionMessage(e))
      })

      if (is.list(fit) && !is.null(fit$error)) {
        losses[li] <- NA_real_
        # do not update state if the fit failed
      } else {
        losses[li] <- .cv_loss(
          U_hat = fit$U,
          Sigma_val = fs$S_va,
          p_list = p_list
        )
        if (losses[li] ==0){
          #### the C hit 0, so it's not a proper solution
          losses[li] = 1e8
        }
        # warm start next lambda
        state <- fit
      }
    }

    list(k = k, losses = losses)
  }

  # -------- run: parallel over folds (or sequential fallback) --------
  did_parallel <- FALSE
  parallel_failed_reason <- NULL

  parallel_ok <- isTRUE(parallel) && K > 1L

  if (parallel_ok) {
    # choose cores: cap at K
    requested <- if (!is.null(nb_cores)) {
      as.integer(nb_cores)
    } else {
      n_cores_str <- Sys.getenv("SLURM_CPUS_PER_TASK")
      if (n_cores_str == "") parallel::detectCores() - 1L else as.integer(n_cores_str)
    }
    requested <- max(1L, requested)
    requested <- min(requested, K)

    .log("[cv][PAR] requested cores=%d (cap at K=%d)", requested, K)

    cl <- NULL
    ok <- tryCatch({
      cl <- setup_parallel_backend(num_cores = requested, verbose = verbose)
      if (is.null(cl)) stop("setup_parallel_backend() returned NULL")

      # set RNG streams (reproducibility if any randomness occurs)
      if (!is.null(rng_seed)) {
        try(parallel::clusterSetRNGStream(cl, iseed = as.integer(rng_seed)), silent = TRUE)
      }

      # limit BLAS threads per worker
      parallel::clusterCall(
        cl,
        function(bt) {
          if (requireNamespace("RhpcBLASctl", quietly = TRUE)) {
            RhpcBLASctl::blas_set_num_threads(as.integer(bt))
            RhpcBLASctl::omp_set_num_threads(as.integer(bt))
          }
          Sys.setenv(OMP_NUM_THREADS = as.character(bt),
                     MKL_NUM_THREADS = as.character(bt),
                     OPENBLAS_NUM_THREADS = as.character(bt))
          NULL
        },
        as.integer(blas_threads)
      )

      # export required functions to PSOCK workers (harmless on FORK)
      exports <- c(
        "%||%", "matmul", "soft_threshold", "sym_inv_sqrt", "top_eigs_sym",
        ".prox_l21_rows", ".prox_l21_groups",
        ".make_folds", ".mask_from_part", ".bd_from_S", ".cv_loss",
        ".admm_sgca_prepare", ".admm_sgca_run"
      )
      parallel::clusterExport(cl, varlist = exports, envir = environment())

      # also export scalar/vector configs used inside worker closure
      parallel::clusterExport(
        cl,
        varlist = c("p_list", "lambdas", "L", "r", "rho", "penalty", "penalize",
                    "weight", "row_weights", "groups_l21", "group_weights",
                    "symmetrize_z", "max_iter", "abs_tol", "rel_tol", "adapt_rho",
                    "mu", "tau_incr", "tau_decr", "sparsity_threshold",
                    "lam_ord", "part_eff", "loss_weight", "relative_loss", "warm_start"),
        envir = environment()
      )

      .log("[cv][PAR] launching parLapply over %d folds...", K)
      res_list <- parallel::parLapply(cl, fold_stats, fun = .worker_fold)

      # fill cv_mat
      for (res in res_list) {
        if (is.list(res) && !is.null(res$k) && !is.null(res$losses)) {
          cv_mat[, res$k] <- res$losses
        }
      }

      did_parallel <- TRUE
      TRUE

    }, error = function(e) {
      parallel_failed_reason <<- conditionMessage(e)
      FALSE
    }, finally = {
      if (!is.null(cl)) {
        try(parallel::stopCluster(cl), silent = TRUE)
      }
    })

    if (!isTRUE(ok)) {
      message(sprintf("[cv][PAR] Parallel attempt FAILED -> falling back to sequential. Reason: %s",
                      parallel_failed_reason))
      did_parallel <- FALSE
    }
  }

  if (!did_parallel) {
    .log("[cv][SEQ] running sequentially over folds...")
    for (k in seq_len(K)) {
      res <- .worker_fold(fold_stats[[k]])
      cv_mat[, res$k] <- res$losses
    }
  }

  n_bad <- sum(!is.finite(cv_mat))
  .log("[cv] post-run non-finite cells: %d / %d", n_bad, length(cv_mat))

  # Require lambdas evaluated on all folds
  row_ok <- rowSums(is.finite(cv_mat)) == K
  if (!any(row_ok)) {
    stop("No lambda was successfully evaluated on all folds. Inspect solver settings / data.")
  }

  cvm <- rowMeans(cv_mat, na.rm = TRUE)
  cvsd <- apply(cv_mat, 1, function(x) {
    m <- sum(is.finite(x))
    if (m <= 1) return(NA_real_)
    stats::sd(x, na.rm = TRUE) / sqrt(m)
  })

  best_rel_idx <- which.min(cvm[row_ok])
  lambda_min <- lambdas[row_ok][best_rel_idx]

  .log("[cv] lambda_min=%g (refit on full data)", lambda_min)

  # Refit on full data (compute canonical directions)
  prep_full <- .admm_sgca_prepare(
    Sigma = S_full,
    Sigma0 = S0_full,
    rho = rho,
    p_list = p_list,
    penalty = penalty,
    penalize = penalize,
    weight = weight,
    row_weights = row_weights,
    groups_l21 = groups_l21,
    group_weights = group_weights,
    symmetrize_z = symmetrize_z,
    sparsity_threshold = sparsity_threshold
  )

  fit_min <- .admm_sgca_run(
    prep = prep_full,
    lambda = lambda_min,
    r = r,
    init = NULL,
    warm_start = "none",
    max_iter = max_iter,
    abs_tol = abs_tol,
    rel_tol = rel_tol,
    adapt_rho = adapt_rho,
    mu = mu,
    tau_incr = tau_incr,
    tau_decr = tau_decr,
    verbose = FALSE,
    compute_canon = TRUE
  )

  out <- list(
    lambdas = lambdas,
    cvloss = cv_mat,
    cvm = cvm,
    cvsd = cvsd,
    lambda_min = lambda_min,
    fit_min = fit_min,
    folds = folds,
    K = K,
    r = r,
    penalty = penalty,
    penalize = penalize,
    loss_part = part_eff,
    relative_loss = relative_loss,
    did_parallel = did_parallel,
    parallel_failed_reason = parallel_failed_reason,
    lambda_order = lambda_order,
    warm_start = warm_start
  )
  class(out) <- "cv_sgcar"
  out
}
